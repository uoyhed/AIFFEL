{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87156224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
      "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "\n",
      "         s4        s5        s6  \n",
      "0 -0.002592  0.019908 -0.017646  \n",
      "1 -0.039493 -0.068330 -0.092204  \n",
      "2 -0.002592  0.002864 -0.025930  \n",
      "3  0.034309  0.022692 -0.009362  \n",
      "4 -0.002592 -0.031991 -0.046641  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "import seaborn as sns\n",
    "diabetes = load_diabetes()\n",
    "diabetes_df = pd.DataFrame(data=diabetes.data,columns=diabetes.feature_names)\n",
    "print(diabetes_df.head())\n",
    "\n",
    "df_X = diabetes.data\n",
    "df_y = diabetes.target\n",
    "df_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47abfeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4c69da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(df_X,df_y,test_size=0.3,random_state=10)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d93b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309, 10), (133, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781bb204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309,), (133,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f582c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(10)\n",
    "b = np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52811566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, W, b):\n",
    "    predictions = 0\n",
    "    for i in range(9):\n",
    "        predictions += X[:, i] * W[i]\n",
    "    predictions += b\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c3dd434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(a, b):\n",
    "    mse = ((a - b) ** 2).mean()  # 두 값의 차이의 제곱의 평균\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b7326bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, W, b, y):\n",
    "    predictions = model(X, W, b)\n",
    "    L = MSE(predictions, y)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52ab0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, W, b, y):\n",
    "    # N은 가중치의 개수\n",
    "    N = len(W)\n",
    "    \n",
    "    # y_pred 준비\n",
    "    y_pred = model(X, W, b)\n",
    "    \n",
    "    # 공식에 맞게 gradient 계산\n",
    "    dW = 1/N * 2 * X.T.dot(y_pred - y)\n",
    "        \n",
    "    # b의 gradient 계산\n",
    "    db = 2 * (y_pred - y).mean()\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca0e657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW: [ -60.64245407  -13.77756008 -189.71985238 -142.69721818  -68.2088867\n",
      "  -55.93041125  127.78313683 -139.07793048 -182.98755829 -123.64023495]\n",
      "db: -303.43635251078206\n"
     ]
    }
   ],
   "source": [
    "dW, db = gradient(df_X, W, b, df_y)\n",
    "print(\"dW:\", dW)\n",
    "print(\"db:\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08a3b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습률 설정\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64afe07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 : Loss 28859.1827\n",
      "Iteration 20 : Loss 28764.1229\n",
      "Iteration 30 : Loss 28669.4369\n",
      "Iteration 40 : Loss 28575.1234\n",
      "Iteration 50 : Loss 28481.1808\n",
      "Iteration 60 : Loss 28387.6076\n",
      "Iteration 70 : Loss 28294.4023\n",
      "Iteration 80 : Loss 28201.5636\n",
      "Iteration 90 : Loss 28109.0899\n",
      "Iteration 100 : Loss 28016.9798\n",
      "Iteration 110 : Loss 27925.2318\n",
      "Iteration 120 : Loss 27833.8445\n",
      "Iteration 130 : Loss 27742.8165\n",
      "Iteration 140 : Loss 27652.1462\n",
      "Iteration 150 : Loss 27561.8324\n",
      "Iteration 160 : Loss 27471.8736\n",
      "Iteration 170 : Loss 27382.2683\n",
      "Iteration 180 : Loss 27293.0152\n",
      "Iteration 190 : Loss 27204.1129\n",
      "Iteration 200 : Loss 27115.5599\n",
      "Iteration 210 : Loss 27027.3549\n",
      "Iteration 220 : Loss 26939.4965\n",
      "Iteration 230 : Loss 26851.9833\n",
      "Iteration 240 : Loss 26764.8139\n",
      "Iteration 250 : Loss 26677.9870\n",
      "Iteration 260 : Loss 26591.5011\n",
      "Iteration 270 : Loss 26505.3550\n",
      "Iteration 280 : Loss 26419.5473\n",
      "Iteration 290 : Loss 26334.0767\n",
      "Iteration 300 : Loss 26248.9417\n",
      "Iteration 310 : Loss 26164.1411\n",
      "Iteration 320 : Loss 26079.6736\n",
      "Iteration 330 : Loss 25995.5377\n",
      "Iteration 340 : Loss 25911.7323\n",
      "Iteration 350 : Loss 25828.2559\n",
      "Iteration 360 : Loss 25745.1072\n",
      "Iteration 370 : Loss 25662.2851\n",
      "Iteration 380 : Loss 25579.7880\n",
      "Iteration 390 : Loss 25497.6149\n",
      "Iteration 400 : Loss 25415.7643\n",
      "Iteration 410 : Loss 25334.2350\n",
      "Iteration 420 : Loss 25253.0257\n",
      "Iteration 430 : Loss 25172.1351\n",
      "Iteration 440 : Loss 25091.5621\n",
      "Iteration 450 : Loss 25011.3052\n",
      "Iteration 460 : Loss 24931.3632\n",
      "Iteration 470 : Loss 24851.7350\n",
      "Iteration 480 : Loss 24772.4192\n",
      "Iteration 490 : Loss 24693.4146\n",
      "Iteration 500 : Loss 24614.7199\n",
      "Iteration 510 : Loss 24536.3340\n",
      "Iteration 520 : Loss 24458.2556\n",
      "Iteration 530 : Loss 24380.4835\n",
      "Iteration 540 : Loss 24303.0164\n",
      "Iteration 550 : Loss 24225.8531\n",
      "Iteration 560 : Loss 24148.9925\n",
      "Iteration 570 : Loss 24072.4333\n",
      "Iteration 580 : Loss 23996.1744\n",
      "Iteration 590 : Loss 23920.2145\n",
      "Iteration 600 : Loss 23844.5524\n",
      "Iteration 610 : Loss 23769.1870\n",
      "Iteration 620 : Loss 23694.1170\n",
      "Iteration 630 : Loss 23619.3414\n",
      "Iteration 640 : Loss 23544.8589\n",
      "Iteration 650 : Loss 23470.6683\n",
      "Iteration 660 : Loss 23396.7686\n",
      "Iteration 670 : Loss 23323.1585\n",
      "Iteration 680 : Loss 23249.8369\n",
      "Iteration 690 : Loss 23176.8026\n",
      "Iteration 700 : Loss 23104.0545\n",
      "Iteration 710 : Loss 23031.5915\n",
      "Iteration 720 : Loss 22959.4125\n",
      "Iteration 730 : Loss 22887.5162\n",
      "Iteration 740 : Loss 22815.9016\n",
      "Iteration 750 : Loss 22744.5676\n",
      "Iteration 760 : Loss 22673.5129\n",
      "Iteration 770 : Loss 22602.7367\n",
      "Iteration 780 : Loss 22532.2376\n",
      "Iteration 790 : Loss 22462.0146\n",
      "Iteration 800 : Loss 22392.0667\n",
      "Iteration 810 : Loss 22322.3927\n",
      "Iteration 820 : Loss 22252.9915\n",
      "Iteration 830 : Loss 22183.8620\n",
      "Iteration 840 : Loss 22115.0033\n",
      "Iteration 850 : Loss 22046.4141\n",
      "Iteration 860 : Loss 21978.0934\n",
      "Iteration 870 : Loss 21910.0402\n",
      "Iteration 880 : Loss 21842.2533\n",
      "Iteration 890 : Loss 21774.7318\n",
      "Iteration 900 : Loss 21707.4746\n",
      "Iteration 910 : Loss 21640.4805\n",
      "Iteration 920 : Loss 21573.7487\n",
      "Iteration 930 : Loss 21507.2780\n",
      "Iteration 940 : Loss 21441.0673\n",
      "Iteration 950 : Loss 21375.1157\n",
      "Iteration 960 : Loss 21309.4221\n",
      "Iteration 970 : Loss 21243.9856\n",
      "Iteration 980 : Loss 21178.8050\n",
      "Iteration 990 : Loss 21113.8793\n",
      "Iteration 1000 : Loss 21049.2076\n",
      "Iteration 1010 : Loss 20984.7889\n",
      "Iteration 1020 : Loss 20920.6220\n",
      "Iteration 1030 : Loss 20856.7061\n",
      "Iteration 1040 : Loss 20793.0401\n",
      "Iteration 1050 : Loss 20729.6231\n",
      "Iteration 1060 : Loss 20666.4539\n",
      "Iteration 1070 : Loss 20603.5318\n",
      "Iteration 1080 : Loss 20540.8556\n",
      "Iteration 1090 : Loss 20478.4244\n",
      "Iteration 1100 : Loss 20416.2372\n",
      "Iteration 1110 : Loss 20354.2931\n",
      "Iteration 1120 : Loss 20292.5911\n",
      "Iteration 1130 : Loss 20231.1302\n",
      "Iteration 1140 : Loss 20169.9094\n",
      "Iteration 1150 : Loss 20108.9279\n",
      "Iteration 1160 : Loss 20048.1846\n",
      "Iteration 1170 : Loss 19987.6786\n",
      "Iteration 1180 : Loss 19927.4090\n",
      "Iteration 1190 : Loss 19867.3749\n",
      "Iteration 1200 : Loss 19807.5752\n",
      "Iteration 1210 : Loss 19748.0090\n",
      "Iteration 1220 : Loss 19688.6755\n",
      "Iteration 1230 : Loss 19629.5737\n",
      "Iteration 1240 : Loss 19570.7027\n",
      "Iteration 1250 : Loss 19512.0615\n",
      "Iteration 1260 : Loss 19453.6493\n",
      "Iteration 1270 : Loss 19395.4652\n",
      "Iteration 1280 : Loss 19337.5081\n",
      "Iteration 1290 : Loss 19279.7773\n",
      "Iteration 1300 : Loss 19222.2719\n",
      "Iteration 1310 : Loss 19164.9908\n",
      "Iteration 1320 : Loss 19107.9333\n",
      "Iteration 1330 : Loss 19051.0985\n",
      "Iteration 1340 : Loss 18994.4854\n",
      "Iteration 1350 : Loss 18938.0932\n",
      "Iteration 1360 : Loss 18881.9211\n",
      "Iteration 1370 : Loss 18825.9680\n",
      "Iteration 1380 : Loss 18770.2332\n",
      "Iteration 1390 : Loss 18714.7159\n",
      "Iteration 1400 : Loss 18659.4150\n",
      "Iteration 1410 : Loss 18604.3299\n",
      "Iteration 1420 : Loss 18549.4595\n",
      "Iteration 1430 : Loss 18494.8031\n",
      "Iteration 1440 : Loss 18440.3598\n",
      "Iteration 1450 : Loss 18386.1288\n",
      "Iteration 1460 : Loss 18332.1092\n",
      "Iteration 1470 : Loss 18278.3001\n",
      "Iteration 1480 : Loss 18224.7008\n",
      "Iteration 1490 : Loss 18171.3104\n",
      "Iteration 1500 : Loss 18118.1281\n",
      "Iteration 1510 : Loss 18065.1531\n",
      "Iteration 1520 : Loss 18012.3845\n",
      "Iteration 1530 : Loss 17959.8214\n",
      "Iteration 1540 : Loss 17907.4632\n",
      "Iteration 1550 : Loss 17855.3089\n",
      "Iteration 1560 : Loss 17803.3579\n",
      "Iteration 1570 : Loss 17751.6091\n",
      "Iteration 1580 : Loss 17700.0619\n",
      "Iteration 1590 : Loss 17648.7155\n",
      "Iteration 1600 : Loss 17597.5690\n",
      "Iteration 1610 : Loss 17546.6217\n",
      "Iteration 1620 : Loss 17495.8728\n",
      "Iteration 1630 : Loss 17445.3214\n",
      "Iteration 1640 : Loss 17394.9668\n",
      "Iteration 1650 : Loss 17344.8083\n",
      "Iteration 1660 : Loss 17294.8450\n",
      "Iteration 1670 : Loss 17245.0761\n",
      "Iteration 1680 : Loss 17195.5009\n",
      "Iteration 1690 : Loss 17146.1187\n",
      "Iteration 1700 : Loss 17096.9285\n",
      "Iteration 1710 : Loss 17047.9298\n",
      "Iteration 1720 : Loss 16999.1217\n",
      "Iteration 1730 : Loss 16950.5035\n",
      "Iteration 1740 : Loss 16902.0744\n",
      "Iteration 1750 : Loss 16853.8336\n",
      "Iteration 1760 : Loss 16805.7805\n",
      "Iteration 1770 : Loss 16757.9142\n",
      "Iteration 1780 : Loss 16710.2341\n",
      "Iteration 1790 : Loss 16662.7393\n",
      "Iteration 1800 : Loss 16615.4292\n",
      "Iteration 1810 : Loss 16568.3030\n",
      "Iteration 1820 : Loss 16521.3600\n",
      "Iteration 1830 : Loss 16474.5995\n",
      "Iteration 1840 : Loss 16428.0207\n",
      "Iteration 1850 : Loss 16381.6229\n",
      "Iteration 1860 : Loss 16335.4054\n",
      "Iteration 1870 : Loss 16289.3675\n",
      "Iteration 1880 : Loss 16243.5085\n",
      "Iteration 1890 : Loss 16197.8276\n",
      "Iteration 1900 : Loss 16152.3241\n",
      "Iteration 1910 : Loss 16106.9974\n",
      "Iteration 1920 : Loss 16061.8467\n",
      "Iteration 1930 : Loss 16016.8714\n",
      "Iteration 1940 : Loss 15972.0707\n",
      "Iteration 1950 : Loss 15927.4440\n",
      "Iteration 1960 : Loss 15882.9905\n",
      "Iteration 1970 : Loss 15838.7096\n",
      "Iteration 1980 : Loss 15794.6006\n",
      "Iteration 1990 : Loss 15750.6628\n",
      "Iteration 2000 : Loss 15706.8955\n",
      "Iteration 2010 : Loss 15663.2981\n",
      "Iteration 2020 : Loss 15619.8698\n",
      "Iteration 2030 : Loss 15576.6100\n",
      "Iteration 2040 : Loss 15533.5181\n",
      "Iteration 2050 : Loss 15490.5933\n",
      "Iteration 2060 : Loss 15447.8351\n",
      "Iteration 2070 : Loss 15405.2426\n",
      "Iteration 2080 : Loss 15362.8154\n",
      "Iteration 2090 : Loss 15320.5527\n",
      "Iteration 2100 : Loss 15278.4538\n",
      "Iteration 2110 : Loss 15236.5182\n",
      "Iteration 2120 : Loss 15194.7452\n",
      "Iteration 2130 : Loss 15153.1340\n",
      "Iteration 2140 : Loss 15111.6842\n",
      "Iteration 2150 : Loss 15070.3950\n",
      "Iteration 2160 : Loss 15029.2659\n",
      "Iteration 2170 : Loss 14988.2961\n",
      "Iteration 2180 : Loss 14947.4850\n",
      "Iteration 2190 : Loss 14906.8320\n",
      "Iteration 2200 : Loss 14866.3366\n",
      "Iteration 2210 : Loss 14825.9980\n",
      "Iteration 2220 : Loss 14785.8156\n",
      "Iteration 2230 : Loss 14745.7888\n",
      "Iteration 2240 : Loss 14705.9171\n",
      "Iteration 2250 : Loss 14666.1997\n",
      "Iteration 2260 : Loss 14626.6361\n",
      "Iteration 2270 : Loss 14587.2256\n",
      "Iteration 2280 : Loss 14547.9677\n",
      "Iteration 2290 : Loss 14508.8618\n",
      "Iteration 2300 : Loss 14469.9071\n",
      "Iteration 2310 : Loss 14431.1033\n",
      "Iteration 2320 : Loss 14392.4496\n",
      "Iteration 2330 : Loss 14353.9454\n",
      "Iteration 2340 : Loss 14315.5901\n",
      "Iteration 2350 : Loss 14277.3833\n",
      "Iteration 2360 : Loss 14239.3242\n",
      "Iteration 2370 : Loss 14201.4123\n",
      "Iteration 2380 : Loss 14163.6470\n",
      "Iteration 2390 : Loss 14126.0277\n",
      "Iteration 2400 : Loss 14088.5539\n",
      "Iteration 2410 : Loss 14051.2250\n",
      "Iteration 2420 : Loss 14014.0403\n",
      "Iteration 2430 : Loss 13976.9993\n",
      "Iteration 2440 : Loss 13940.1016\n",
      "Iteration 2450 : Loss 13903.3463\n",
      "Iteration 2460 : Loss 13866.7331\n",
      "Iteration 2470 : Loss 13830.2614\n",
      "Iteration 2480 : Loss 13793.9305\n",
      "Iteration 2490 : Loss 13757.7400\n",
      "Iteration 2500 : Loss 13721.6892\n",
      "Iteration 2510 : Loss 13685.7777\n",
      "Iteration 2520 : Loss 13650.0048\n",
      "Iteration 2530 : Loss 13614.3701\n",
      "Iteration 2540 : Loss 13578.8729\n",
      "Iteration 2550 : Loss 13543.5128\n",
      "Iteration 2560 : Loss 13508.2891\n",
      "Iteration 2570 : Loss 13473.2014\n",
      "Iteration 2580 : Loss 13438.2491\n",
      "Iteration 2590 : Loss 13403.4316\n",
      "Iteration 2600 : Loss 13368.7485\n",
      "Iteration 2610 : Loss 13334.1991\n",
      "Iteration 2620 : Loss 13299.7831\n",
      "Iteration 2630 : Loss 13265.4997\n",
      "Iteration 2640 : Loss 13231.3486\n",
      "Iteration 2650 : Loss 13197.3292\n",
      "Iteration 2660 : Loss 13163.4409\n",
      "Iteration 2670 : Loss 13129.6833\n",
      "Iteration 2680 : Loss 13096.0558\n",
      "Iteration 2690 : Loss 13062.5579\n",
      "Iteration 2700 : Loss 13029.1891\n",
      "Iteration 2710 : Loss 12995.9489\n",
      "Iteration 2720 : Loss 12962.8367\n",
      "Iteration 2730 : Loss 12929.8522\n",
      "Iteration 2740 : Loss 12896.9946\n",
      "Iteration 2750 : Loss 12864.2637\n",
      "Iteration 2760 : Loss 12831.6588\n",
      "Iteration 2770 : Loss 12799.1795\n",
      "Iteration 2780 : Loss 12766.8252\n",
      "Iteration 2790 : Loss 12734.5955\n",
      "Iteration 2800 : Loss 12702.4898\n",
      "Iteration 2810 : Loss 12670.5077\n",
      "Iteration 2820 : Loss 12638.6488\n",
      "Iteration 2830 : Loss 12606.9124\n",
      "Iteration 2840 : Loss 12575.2981\n",
      "Iteration 2850 : Loss 12543.8055\n",
      "Iteration 2860 : Loss 12512.4340\n",
      "Iteration 2870 : Loss 12481.1831\n",
      "Iteration 2880 : Loss 12450.0525\n",
      "Iteration 2890 : Loss 12419.0416\n",
      "Iteration 2900 : Loss 12388.1499\n",
      "Iteration 2910 : Loss 12357.3769\n",
      "Iteration 2920 : Loss 12326.7223\n",
      "Iteration 2930 : Loss 12296.1855\n",
      "Iteration 2940 : Loss 12265.7660\n",
      "Iteration 2950 : Loss 12235.4635\n",
      "Iteration 2960 : Loss 12205.2774\n",
      "Iteration 2970 : Loss 12175.2072\n",
      "Iteration 2980 : Loss 12145.2526\n",
      "Iteration 2990 : Loss 12115.4130\n",
      "Iteration 3000 : Loss 12085.6880\n",
      "Iteration 3010 : Loss 12056.0771\n",
      "Iteration 3020 : Loss 12026.5800\n",
      "Iteration 3030 : Loss 11997.1961\n",
      "Iteration 3040 : Loss 11967.9249\n",
      "Iteration 3050 : Loss 11938.7661\n",
      "Iteration 3060 : Loss 11909.7192\n",
      "Iteration 3070 : Loss 11880.7838\n",
      "Iteration 3080 : Loss 11851.9594\n",
      "Iteration 3090 : Loss 11823.2455\n",
      "Iteration 3100 : Loss 11794.6418\n",
      "Iteration 3110 : Loss 11766.1478\n",
      "Iteration 3120 : Loss 11737.7631\n",
      "Iteration 3130 : Loss 11709.4872\n",
      "Iteration 3140 : Loss 11681.3197\n",
      "Iteration 3150 : Loss 11653.2601\n",
      "Iteration 3160 : Loss 11625.3082\n",
      "Iteration 3170 : Loss 11597.4633\n",
      "Iteration 3180 : Loss 11569.7251\n",
      "Iteration 3190 : Loss 11542.0932\n",
      "Iteration 3200 : Loss 11514.5672\n",
      "Iteration 3210 : Loss 11487.1465\n",
      "Iteration 3220 : Loss 11459.8309\n",
      "Iteration 3230 : Loss 11432.6199\n",
      "Iteration 3240 : Loss 11405.5131\n",
      "Iteration 3250 : Loss 11378.5101\n",
      "Iteration 3260 : Loss 11351.6104\n",
      "Iteration 3270 : Loss 11324.8136\n",
      "Iteration 3280 : Loss 11298.1194\n",
      "Iteration 3290 : Loss 11271.5274\n",
      "Iteration 3300 : Loss 11245.0371\n",
      "Iteration 3310 : Loss 11218.6481\n",
      "Iteration 3320 : Loss 11192.3600\n",
      "Iteration 3330 : Loss 11166.1725\n",
      "Iteration 3340 : Loss 11140.0851\n",
      "Iteration 3350 : Loss 11114.0975\n",
      "Iteration 3360 : Loss 11088.2092\n",
      "Iteration 3370 : Loss 11062.4198\n",
      "Iteration 3380 : Loss 11036.7290\n",
      "Iteration 3390 : Loss 11011.1363\n",
      "Iteration 3400 : Loss 10985.6415\n",
      "Iteration 3410 : Loss 10960.2440\n",
      "Iteration 3420 : Loss 10934.9435\n",
      "Iteration 3430 : Loss 10909.7397\n",
      "Iteration 3440 : Loss 10884.6321\n",
      "Iteration 3450 : Loss 10859.6203\n",
      "Iteration 3460 : Loss 10834.7041\n",
      "Iteration 3470 : Loss 10809.8829\n",
      "Iteration 3480 : Loss 10785.1565\n",
      "Iteration 3490 : Loss 10760.5244\n",
      "Iteration 3500 : Loss 10735.9863\n",
      "Iteration 3510 : Loss 10711.5418\n",
      "Iteration 3520 : Loss 10687.1905\n",
      "Iteration 3530 : Loss 10662.9321\n",
      "Iteration 3540 : Loss 10638.7662\n",
      "Iteration 3550 : Loss 10614.6924\n",
      "Iteration 3560 : Loss 10590.7104\n",
      "Iteration 3570 : Loss 10566.8198\n",
      "Iteration 3580 : Loss 10543.0203\n",
      "Iteration 3590 : Loss 10519.3114\n",
      "Iteration 3600 : Loss 10495.6928\n",
      "Iteration 3610 : Loss 10472.1643\n",
      "Iteration 3620 : Loss 10448.7253\n",
      "Iteration 3630 : Loss 10425.3756\n",
      "Iteration 3640 : Loss 10402.1148\n",
      "Iteration 3650 : Loss 10378.9425\n",
      "Iteration 3660 : Loss 10355.8585\n",
      "Iteration 3670 : Loss 10332.8623\n",
      "Iteration 3680 : Loss 10309.9536\n",
      "Iteration 3690 : Loss 10287.1321\n",
      "Iteration 3700 : Loss 10264.3974\n",
      "Iteration 3710 : Loss 10241.7491\n",
      "Iteration 3720 : Loss 10219.1870\n",
      "Iteration 3730 : Loss 10196.7107\n",
      "Iteration 3740 : Loss 10174.3198\n",
      "Iteration 3750 : Loss 10152.0141\n",
      "Iteration 3760 : Loss 10129.7931\n",
      "Iteration 3770 : Loss 10107.6565\n",
      "Iteration 3780 : Loss 10085.6041\n",
      "Iteration 3790 : Loss 10063.6355\n",
      "Iteration 3800 : Loss 10041.7502\n",
      "Iteration 3810 : Loss 10019.9482\n",
      "Iteration 3820 : Loss 9998.2288\n",
      "Iteration 3830 : Loss 9976.5920\n",
      "Iteration 3840 : Loss 9955.0373\n",
      "Iteration 3850 : Loss 9933.5644\n",
      "Iteration 3860 : Loss 9912.1729\n",
      "Iteration 3870 : Loss 9890.8627\n",
      "Iteration 3880 : Loss 9869.6332\n",
      "Iteration 3890 : Loss 9848.4843\n",
      "Iteration 3900 : Loss 9827.4156\n",
      "Iteration 3910 : Loss 9806.4268\n",
      "Iteration 3920 : Loss 9785.5176\n",
      "Iteration 3930 : Loss 9764.6876\n",
      "Iteration 3940 : Loss 9743.9366\n",
      "Iteration 3950 : Loss 9723.2642\n",
      "Iteration 3960 : Loss 9702.6701\n",
      "Iteration 3970 : Loss 9682.1540\n",
      "Iteration 3980 : Loss 9661.7156\n",
      "Iteration 3990 : Loss 9641.3547\n",
      "Iteration 4000 : Loss 9621.0708\n",
      "Iteration 4010 : Loss 9600.8637\n",
      "Iteration 4020 : Loss 9580.7331\n",
      "Iteration 4030 : Loss 9560.6786\n",
      "Iteration 4040 : Loss 9540.7001\n",
      "Iteration 4050 : Loss 9520.7971\n",
      "Iteration 4060 : Loss 9500.9694\n",
      "Iteration 4070 : Loss 9481.2167\n",
      "Iteration 4080 : Loss 9461.5387\n",
      "Iteration 4090 : Loss 9441.9351\n",
      "Iteration 4100 : Loss 9422.4056\n",
      "Iteration 4110 : Loss 9402.9499\n",
      "Iteration 4120 : Loss 9383.5677\n",
      "Iteration 4130 : Loss 9364.2587\n",
      "Iteration 4140 : Loss 9345.0227\n",
      "Iteration 4150 : Loss 9325.8593\n",
      "Iteration 4160 : Loss 9306.7682\n",
      "Iteration 4170 : Loss 9287.7493\n",
      "Iteration 4180 : Loss 9268.8021\n",
      "Iteration 4190 : Loss 9249.9265\n",
      "Iteration 4200 : Loss 9231.1221\n",
      "Iteration 4210 : Loss 9212.3886\n",
      "Iteration 4220 : Loss 9193.7258\n",
      "Iteration 4230 : Loss 9175.1333\n",
      "Iteration 4240 : Loss 9156.6110\n",
      "Iteration 4250 : Loss 9138.1585\n",
      "Iteration 4260 : Loss 9119.7756\n",
      "Iteration 4270 : Loss 9101.4620\n",
      "Iteration 4280 : Loss 9083.2173\n",
      "Iteration 4290 : Loss 9065.0414\n",
      "Iteration 4300 : Loss 9046.9340\n",
      "Iteration 4310 : Loss 9028.8947\n",
      "Iteration 4320 : Loss 9010.9234\n",
      "Iteration 4330 : Loss 8993.0197\n",
      "Iteration 4340 : Loss 8975.1834\n",
      "Iteration 4350 : Loss 8957.4143\n",
      "Iteration 4360 : Loss 8939.7120\n",
      "Iteration 4370 : Loss 8922.0763\n",
      "Iteration 4380 : Loss 8904.5069\n",
      "Iteration 4390 : Loss 8887.0036\n",
      "Iteration 4400 : Loss 8869.5661\n",
      "Iteration 4410 : Loss 8852.1942\n",
      "Iteration 4420 : Loss 8834.8876\n",
      "Iteration 4430 : Loss 8817.6460\n",
      "Iteration 4440 : Loss 8800.4691\n",
      "Iteration 4450 : Loss 8783.3568\n",
      "Iteration 4460 : Loss 8766.3088\n",
      "Iteration 4470 : Loss 8749.3248\n",
      "Iteration 4480 : Loss 8732.4045\n",
      "Iteration 4490 : Loss 8715.5478\n",
      "Iteration 4500 : Loss 8698.7543\n",
      "Iteration 4510 : Loss 8682.0238\n",
      "Iteration 4520 : Loss 8665.3561\n",
      "Iteration 4530 : Loss 8648.7509\n",
      "Iteration 4540 : Loss 8632.2080\n",
      "Iteration 4550 : Loss 8615.7271\n",
      "Iteration 4560 : Loss 8599.3080\n",
      "Iteration 4570 : Loss 8582.9504\n",
      "Iteration 4580 : Loss 8566.6541\n",
      "Iteration 4590 : Loss 8550.4189\n",
      "Iteration 4600 : Loss 8534.2444\n",
      "Iteration 4610 : Loss 8518.1306\n",
      "Iteration 4620 : Loss 8502.0771\n",
      "Iteration 4630 : Loss 8486.0836\n",
      "Iteration 4640 : Loss 8470.1501\n",
      "Iteration 4650 : Loss 8454.2761\n",
      "Iteration 4660 : Loss 8438.4615\n",
      "Iteration 4670 : Loss 8422.7061\n",
      "Iteration 4680 : Loss 8407.0097\n",
      "Iteration 4690 : Loss 8391.3719\n",
      "Iteration 4700 : Loss 8375.7925\n",
      "Iteration 4710 : Loss 8360.2714\n",
      "Iteration 4720 : Loss 8344.8083\n",
      "Iteration 4730 : Loss 8329.4029\n",
      "Iteration 4740 : Loss 8314.0551\n",
      "Iteration 4750 : Loss 8298.7646\n",
      "Iteration 4760 : Loss 8283.5312\n",
      "Iteration 4770 : Loss 8268.3547\n",
      "Iteration 4780 : Loss 8253.2348\n",
      "Iteration 4790 : Loss 8238.1713\n",
      "Iteration 4800 : Loss 8223.1640\n",
      "Iteration 4810 : Loss 8208.2127\n",
      "Iteration 4820 : Loss 8193.3171\n",
      "Iteration 4830 : Loss 8178.4771\n",
      "Iteration 4840 : Loss 8163.6924\n",
      "Iteration 4850 : Loss 8148.9628\n",
      "Iteration 4860 : Loss 8134.2880\n",
      "Iteration 4870 : Loss 8119.6680\n",
      "Iteration 4880 : Loss 8105.1023\n",
      "Iteration 4890 : Loss 8090.5910\n",
      "Iteration 4900 : Loss 8076.1336\n",
      "Iteration 4910 : Loss 8061.7300\n",
      "Iteration 4920 : Loss 8047.3801\n",
      "Iteration 4930 : Loss 8033.0835\n",
      "Iteration 4940 : Loss 8018.8401\n",
      "Iteration 4950 : Loss 8004.6497\n",
      "Iteration 4960 : Loss 7990.5120\n",
      "Iteration 4970 : Loss 7976.4269\n",
      "Iteration 4980 : Loss 7962.3941\n",
      "Iteration 4990 : Loss 7948.4135\n",
      "Iteration 5000 : Loss 7934.4848\n",
      "Iteration 5010 : Loss 7920.6078\n",
      "Iteration 5020 : Loss 7906.7823\n",
      "Iteration 5030 : Loss 7893.0082\n",
      "Iteration 5040 : Loss 7879.2852\n",
      "Iteration 5050 : Loss 7865.6131\n",
      "Iteration 5060 : Loss 7851.9917\n",
      "Iteration 5070 : Loss 7838.4209\n",
      "Iteration 5080 : Loss 7824.9004\n",
      "Iteration 5090 : Loss 7811.4300\n",
      "Iteration 5100 : Loss 7798.0095\n",
      "Iteration 5110 : Loss 7784.6387\n",
      "Iteration 5120 : Loss 7771.3175\n",
      "Iteration 5130 : Loss 7758.0456\n",
      "Iteration 5140 : Loss 7744.8229\n",
      "Iteration 5150 : Loss 7731.6491\n",
      "Iteration 5160 : Loss 7718.5241\n",
      "Iteration 5170 : Loss 7705.4476\n",
      "Iteration 5180 : Loss 7692.4196\n",
      "Iteration 5190 : Loss 7679.4397\n",
      "Iteration 5200 : Loss 7666.5078\n",
      "Iteration 5210 : Loss 7653.6237\n",
      "Iteration 5220 : Loss 7640.7873\n",
      "Iteration 5230 : Loss 7627.9982\n",
      "Iteration 5240 : Loss 7615.2565\n",
      "Iteration 5250 : Loss 7602.5617\n",
      "Iteration 5260 : Loss 7589.9139\n",
      "Iteration 5270 : Loss 7577.3128\n",
      "Iteration 5280 : Loss 7564.7581\n",
      "Iteration 5290 : Loss 7552.2498\n",
      "Iteration 5300 : Loss 7539.7876\n",
      "Iteration 5310 : Loss 7527.3714\n",
      "Iteration 5320 : Loss 7515.0010\n",
      "Iteration 5330 : Loss 7502.6762\n",
      "Iteration 5340 : Loss 7490.3968\n",
      "Iteration 5350 : Loss 7478.1627\n",
      "Iteration 5360 : Loss 7465.9736\n",
      "Iteration 5370 : Loss 7453.8294\n",
      "Iteration 5380 : Loss 7441.7299\n",
      "Iteration 5390 : Loss 7429.6750\n",
      "Iteration 5400 : Loss 7417.6644\n",
      "Iteration 5410 : Loss 7405.6980\n",
      "Iteration 5420 : Loss 7393.7757\n",
      "Iteration 5430 : Loss 7381.8972\n",
      "Iteration 5440 : Loss 7370.0623\n",
      "Iteration 5450 : Loss 7358.2710\n",
      "Iteration 5460 : Loss 7346.5229\n",
      "Iteration 5470 : Loss 7334.8181\n",
      "Iteration 5480 : Loss 7323.1562\n",
      "Iteration 5490 : Loss 7311.5372\n",
      "Iteration 5500 : Loss 7299.9608\n",
      "Iteration 5510 : Loss 7288.4269\n",
      "Iteration 5520 : Loss 7276.9353\n",
      "Iteration 5530 : Loss 7265.4858\n",
      "Iteration 5540 : Loss 7254.0784\n",
      "Iteration 5550 : Loss 7242.7127\n",
      "Iteration 5560 : Loss 7231.3888\n",
      "Iteration 5570 : Loss 7220.1063\n",
      "Iteration 5580 : Loss 7208.8652\n",
      "Iteration 5590 : Loss 7197.6652\n",
      "Iteration 5600 : Loss 7186.5062\n",
      "Iteration 5610 : Loss 7175.3881\n",
      "Iteration 5620 : Loss 7164.3107\n",
      "Iteration 5630 : Loss 7153.2738\n",
      "Iteration 5640 : Loss 7142.2773\n",
      "Iteration 5650 : Loss 7131.3210\n",
      "Iteration 5660 : Loss 7120.4047\n",
      "Iteration 5670 : Loss 7109.5283\n",
      "Iteration 5680 : Loss 7098.6917\n",
      "Iteration 5690 : Loss 7087.8947\n",
      "Iteration 5700 : Loss 7077.1371\n",
      "Iteration 5710 : Loss 7066.4187\n",
      "Iteration 5720 : Loss 7055.7395\n",
      "Iteration 5730 : Loss 7045.0993\n",
      "Iteration 5740 : Loss 7034.4978\n",
      "Iteration 5750 : Loss 7023.9350\n",
      "Iteration 5760 : Loss 7013.4108\n",
      "Iteration 5770 : Loss 7002.9249\n",
      "Iteration 5780 : Loss 6992.4772\n",
      "Iteration 5790 : Loss 6982.0676\n",
      "Iteration 5800 : Loss 6971.6958\n",
      "Iteration 5810 : Loss 6961.3619\n",
      "Iteration 5820 : Loss 6951.0655\n",
      "Iteration 5830 : Loss 6940.8067\n",
      "Iteration 5840 : Loss 6930.5851\n",
      "Iteration 5850 : Loss 6920.4007\n",
      "Iteration 5860 : Loss 6910.2534\n",
      "Iteration 5870 : Loss 6900.1429\n",
      "Iteration 5880 : Loss 6890.0692\n",
      "Iteration 5890 : Loss 6880.0321\n",
      "Iteration 5900 : Loss 6870.0314\n",
      "Iteration 5910 : Loss 6860.0670\n",
      "Iteration 5920 : Loss 6850.1388\n",
      "Iteration 5930 : Loss 6840.2466\n",
      "Iteration 5940 : Loss 6830.3903\n",
      "Iteration 5950 : Loss 6820.5698\n",
      "Iteration 5960 : Loss 6810.7849\n",
      "Iteration 5970 : Loss 6801.0354\n",
      "Iteration 5980 : Loss 6791.3212\n",
      "Iteration 5990 : Loss 6781.6423\n",
      "Iteration 6000 : Loss 6771.9983\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for i in range(1, 6001):\n",
    "    dW, db = gradient(X_train, W, b, y_train)\n",
    "    W -= LEARNING_RATE * dW\n",
    "    b -= LEARNING_RATE * db\n",
    "    L = loss(X_train, W, b, y_train)\n",
    "    losses.append(L)\n",
    "    if i % 10 == 0:\n",
    "        print('Iteration %d : Loss %0.4f' % (i, L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea36d01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model(X_test, W, b)\n",
    "plt.scatter(X_test[:,0],y_test, label='y_test')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.scatter(X_test[:,0],y_pred, label='y_pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9575a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13c832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354a33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8432b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48ab95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29f694f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0        81        0.0       3          13     16  \n",
       "1        80        0.0       8          32     40  \n",
       "2        80        0.0       5          27     32  \n",
       "3        75        0.0       3          10     13  \n",
       "4        75        0.0       0           1      1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 자전거 타는 사람은 몇 명?\n",
    "#데이터 확인하기\n",
    "train = pd.read_csv('~/data/data/bike-sharing-demand/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2704e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10886 entries, 0 to 10885\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   datetime    10886 non-null  datetime64[ns]\n",
      " 1   season      10886 non-null  int64         \n",
      " 2   holiday     10886 non-null  int64         \n",
      " 3   workingday  10886 non-null  int64         \n",
      " 4   weather     10886 non-null  int64         \n",
      " 5   temp        10886 non-null  float64       \n",
      " 6   atemp       10886 non-null  float64       \n",
      " 7   humidity    10886 non-null  int64         \n",
      " 8   windspeed   10886 non-null  float64       \n",
      " 9   casual      10886 non-null  int64         \n",
      " 10  registered  10886 non-null  int64         \n",
      " 11  count       10886 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(3), int64(8)\n",
      "memory usage: 1020.7 KB\n"
     ]
    }
   ],
   "source": [
    "train['datetime'] = pd.to_datetime(train['datetime']) #train의 datetime을 판다스의 to_datetime을 이용해주고 ()안에 train[datetime] 을 지정해줘서 문자열 -> datetime으로 변환 \n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d49cd994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0 2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1 2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2 2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3 2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4 2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  year  month  day  hour  \\\n",
       "0        81        0.0       3          13     16  2011      1    1     0   \n",
       "1        80        0.0       8          32     40  2011      1    1     1   \n",
       "2        80        0.0       5          27     32  2011      1    1     2   \n",
       "3        75        0.0       3          10     13  2011      1    1     3   \n",
       "4        75        0.0       0           1      1  2011      1    1     4   \n",
       "\n",
       "   minute  second  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "train['year'] = pd.DatetimeIndex(train['datetime']).year\n",
    "train['month'] = pd.DatetimeIndex(train['datetime']).month\n",
    "train['day'] = pd.DatetimeIndex(train['datetime']).day\n",
    "train['hour'] = pd.DatetimeIndex(train['datetime']).hour\n",
    "train['minute'] = pd.DatetimeIndex(train['datetime']).minute\n",
    "train['second'] = pd.DatetimeIndex(train['datetime']).second\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67eb9fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "276d8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['casual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52a31241",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['registered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a612b3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c4db0ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train,train,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87cf6576",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 3 required positional arguments: 'self', 'X', and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32/4058133044.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 3 required positional arguments: 'self', 'X', and 'y'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression\n",
    "lr.fit()\n",
    "y_pred = lr.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "babf9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x,w,b):\n",
    "    y = x * w + b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "11f3cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(a,b):  \n",
    "    mse = ((a-b)**2).mean()\n",
    "    rmse = mse ** 0.5\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6172b77c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32/1112852171.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "rmse = RMSE(predictions, y)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a4d76da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실함수\n",
    "def loss(x,w,b,y):\n",
    "    predictions = model(x,w,b)\n",
    "    L = RMSE(predictions,y)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544b0630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2cffdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b956c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
